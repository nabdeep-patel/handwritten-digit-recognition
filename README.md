# Handwritten Digit Recognition using MNIST Data

## Deployed Link
[![GitHub](https://img.shields.io/badge/Github-Repository-blue?style=flat-square&logo=github)](https://github.com/nabdeep-patel)[![Open app](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://handwritten-digit-recognition-np.streamlit.app/)<a href="[https://colab.research.google.com/github/nabdeep-patel/handwritten-digit-recognition/blob/main/Handwritten_Digit_Classification.ipynb](https://drive.google.com/file/d/1NMB8nkoAxM-wnV9gCdC12JyrscHml3vv/view?usp=sharing)"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>

Streamlit App: https://handwritten-digit-recognition-np.streamlit.app

Colab: https://drive.google.com/file/d/1NMB8nkoAxM-wnV9gCdC12JyrscHml3vv/view?usp=sharing

Github Repository: https://github.com/nabdeep-patel/handwritten-digit-recognition

## Youtube Report
[https://www.youtube.com/watch?v=MBAd2XSiwsI](https://www.youtube.com/watch?v=MBAd2XSiwsI)
[![IMAGE ALT TEXT HERE][(https://img.youtube.com/vi/MBAd2XSiwsI/0.jpg)](https://www.youtube.com/watch?v=MBAd2XSiwsI)]

## Project Overview
üìù In this project, I have developed a model capable of accurately classifying and recognizing handwritten digits using the MNIST Data. Leveraging the power of machine learning, particularly utilizing the Relu Function.
Subsequently, we evaluated its performance on a separate test dataset. Our model got a test accuracy of **97%**.

## About Relu
1. **Definition:** ReLU stands for Rectified Linear Unit. It is an activation function that introduces non-linearity to the neural network by outputting the input directly if it is positive, and zero otherwise.
2. **Mathematical Expression:** The ReLU function is defined as **f(x)=max(0,x)**, where **x** is the input to the function and **f(x)** is the output.
3. **Simple and Efficient:** ReLU is computationally efficient and easy to implement, making it popular in deep learning models.
4. **Non-linear Activation:** ReLU introduces non-linearity to the neural network, allowing it to learn complex relationships between features in the data.

üîç **Model Architecture:**
1. **Input Layer:** Accepts the flattened pixel values of the input image.
2. **Dense Layer:** Comprising multiple neurons to extract features from the data.
3. **Activation Function:** Injects non-linearity into the model.
4. **Output Layer:** Yields the final prediction for the digit class.

## Connect with me
üöÄ If you liked my content, Please star this repository and use it in your projects by forking it. It will keep me motivated and help me provide better contents.
Feel free to explore further and connect with me on GitHub, LinkedIn, or via my personal website.

[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=flat-square&logo=github)](https://github.com/nabdeep-patel)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=flat-square&logo=linkedin)](https://www.linkedin.com/in/nabdeeppatel)
[![Website](https://img.shields.io/badge/Personal-Website-blue?style=flat-square&logo=chrome)](https://linktr.ee/nabdeeppatel/store)

Let's continue to innovate and create meaningful solutions together. üöÄüî¨‚ú®
